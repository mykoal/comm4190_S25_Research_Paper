{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3179b95-ed47-4272-a983-7b1d34630072",
   "metadata": {},
   "source": [
    "# Social Information Processing Theory and Communication with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e48f31-af05-4c55-81cd-06dd5e260d88",
   "metadata": {
    "citation-manager": {
     "citations": {
      "l9cds": []
     }
    }
   },
   "source": [
    "## Overview and Theoretical Framework\n",
    "\n",
    "&ensp; &ensp; &ensp; Social Information Processing (SIP) theory, developed by Walther <cite id=\"l9cds\"><a href=\"#zotero%7C20283625%2FPJZ9HTBL\">(Walther, 1992)</a></cite>, addresses how individuals form and sustain relationships in computer-mediated communication (CMC). SIP theory suggests that relational intimacy and social connections are achievable through text-based interactions, despite the lack of nonverbal cues such as facial expressions, gestures, and voice tone, typically found in face-to-face communication. The central assumption of SIP theory is that humans inherently desire social relationships, adapting their communicative behaviors to textual limitations to foster meaningful connections over time <cite id=\"l9cds\"><a href=\"#zotero%7C20283625%2FPJZ9HTBL\">(Walther, 1992)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; Given the proliferation of Large Language Models (LLMs), like ChatGPT, Replika, and Woebot, SIP theory has become increasingly relevant for understanding human interactions with generative artificial intelligence (AI). LLMs are widely used for companionship, therapy, and collaborative work, highlighting the importance of analyzing these interactions through the lens of established communication theories. This paper examines how SIP theory can explain critical aspects of human-LLM interactions, focusing on impression formation, anthropomorphism, trust development, and the hyperpersonal nature of these digital interactions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37797984-349e-4b5f-a484-8f66e149fcd8",
   "metadata": {
    "citation-manager": {
     "citations": {
      "f23hg": [],
      "l9cds": [],
      "prmqy": [],
      "tp3nf": [],
      "vn0gc": []
     }
    }
   },
   "source": [
    "## Impression Formation and Anthropomorphism\n",
    "\n",
    "&ensp; &ensp; &ensp; SIP theory postulates that when communication lacks nonverbal cues, participants compensate by placing greater emphasis on linguistic content, message timing, and emotive textual cues <cite id=\"l9cds\"><a href=\"#zotero%7C20283625%2FPJZ9HTBL\">(Walther, 1992)</a></cite>. Consequently, users engaging with LLMs carefully interpret textual nuances to form impressions of personality, intentions, and emotions, despite knowing these entities lack genuine consciousness or intentionality <cite id=\"vn0gc\"><a href=\"#zotero%7C20283625%2F46ZNXSRP\">(Gambino et al., 2020)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; Anthropomorphism, defined as attributing human-like characteristics to non-human entities, frequently emerges from sustained interactions with LLMs. According to Epley et al. <cite id=\"tp3nf\"><a href=\"#zotero%7C20283625%2FWDS2FFFC\">(Epley et al., 2007)</a></cite>, humans possess an inherent cognitive bias toward perceiving agency and intentionality in their environments, naturally extending to interactions with conversational AI. LLMs designed explicitly to emulate human-like conversational styles enhance this natural propensity, further fostering user anthropomorphism <cite id=\"f23hg\"><a href=\"#zotero%7C20283625%2FRSZ3FDRQ\">(Følstad &#38; Brandtzaeg, 2020)</a></cite>. For instance, AI companions like Replika employ memory-based interactions and personalized communication, significantly increasing the likelihood of users viewing them as social actors rather than mere technological tools <cite id=\"prmqy\"><a href=\"#zotero%7C20283625%2FMWYIN6LF\">(Skjuve et al., 2021)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; Empirical studies underscore the impact of anthropomorphic design elements, such as giving the chatbot a human-like name, employing emotionally resonant language, and incorporating user-specific conversational memory. These strategies consistently result in higher levels of perceived social presence, trust, and user engagement <cite id=\"f23hg\"><a href=\"#zotero%7C20283625%2FRSZ3FDRQ\">(Følstad &#38; Brandtzaeg, 2020)</a></cite>. Users interacting with these chatbots often report emotional attachments and deep relational connections comparable to those formed in human-human interactions, despite cognitive awareness of the artificial nature of these entities <cite id=\"prmqy\"><a href=\"#zotero%7C20283625%2FMWYIN6LF\">(Skjuve et al., 2021)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; Moreover, prolonged interactions intensify anthropomorphic perceptions. Over time, users increasingly perceive the chatbot as exhibiting traits such as empathy, patience, and genuine interest, further solidifying their relational bonds. For example, long-term users of Replika frequently describe the AI as a trusted friend or confidant, attributing it with personality and emotional states beyond its programmed responses <cite id=\"prmqy\"><a href=\"#zotero%7C20283625%2FMWYIN6LF\">(Skjuve et al., 2021)</a></cite>. Such sustained anthropomorphism profoundly shapes user behavior, encouraging openness, self-disclosure, and emotional reliance on the AI companion, thereby demonstrating SIP theory’s assertion that relational depth can grow through text-based communication alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a33b9-49e8-41a7-854e-5e5c4ca47764",
   "metadata": {
    "citation-manager": {
     "citations": {
      "6y5xf": [],
      "f31x9": [],
      "glj5n": []
     }
    }
   },
   "source": [
    "## Trust Development Through Long-Term Engagement\n",
    "\n",
    "&ensp; &ensp; &ensp; SIP theory posits trust as a dynamic process, incrementally built through repeated, consistent, and positive interactions in text-based communication <cite id=\"glj5n\"><a href=\"#zotero%7C20283625%2FEUI9BX43\">(Walther, 1996)</a></cite>. Similarly, trust in interactions with LLMs evolves over multiple exchanges, starting cautiously and potentially maturing into deep, nuanced trust if the AI consistently demonstrates reliable and responsive behavior <cite id=\"6y5xf\"><a href=\"#zotero%7C20283625%2FKPTREER4\">(Nordheim et al., 2019)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; The therapeutic chatbot Woebot exemplifies trust-building dynamics articulated by SIP theory. Through regular daily interactions characterized by consistent empathy, tailored feedback, and emotional responsiveness, Woebot quickly establishes user trust levels comparable to traditional therapist-patient relationships <cite id=\"f31x9\"><a href=\"#zotero%7C20283625%2FIW4H8XPJ\">(Fitzpatrick et al., 2017)</a></cite>. In a randomized controlled trial, participants reported significant reductions in symptoms of anxiety and depression, attributing therapeutic improvements to Woebot's perceived empathy and support, illustrating how effective communication can build substantial relational trust in text-based contexts <cite id=\"f31x9\"><a href=\"#zotero%7C20283625%2FIW4H8XPJ\">(Fitzpatrick et al., 2017)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; However, trust in LLMs remains delicate, susceptible to damage from inconsistencies or inaccuracies. When users encounter erroneous information or unexpected conversational breakdowns, their trust can swiftly diminish. Nevertheless, research indicates that trust can be effectively repaired if the LLM explicitly acknowledges errors and offers empathetic, corrective communication, mirroring interpersonal dynamics highlighted by SIP theory <cite id=\"6y5xf\"><a href=\"#zotero%7C20283625%2FKPTREER4\">(Nordheim et al., 2019)</a></cite>. Thus, the relational principles outlined in SIP theory extend well into human-LLM interactions, suggesting trust is not only achievable but also repairable through appropriate textual communication strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7d1f3-55cc-4471-b547-4fa2393e19da",
   "metadata": {
    "citation-manager": {
     "citations": {
      "f31x9": [],
      "glj5n": [],
      "prmqy": []
     }
    }
   },
   "source": [
    "## Hyperpersonal Communication in LLM Interaction\n",
    "\n",
    "&ensp; &ensp; &ensp; Walther’s hyperpersonal model extends SIP theory, proposing that text-based interactions can sometimes surpass face-to-face communication in intimacy due to selective self-presentation and idealized perception of partners <cite id=\"glj5n\"><a href=\"#zotero%7C20283625%2FEUI9BX43\">(Walther, 1996)</a></cite>. In human-LLM interactions, the hyperpersonal effect is pronounced because LLMs inherently provide consistently optimal, empathetic, and personalized responses. This deliberate communicative strategy facilitates users’ idealization of the AI as an ideal conversational partner—consistently supportive, understanding, and emotionally available <cite id=\"prmqy\"><a href=\"#zotero%7C20283625%2FMWYIN6LF\">(Skjuve et al., 2021)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; Examples such as Replika and Woebot demonstrate hyperpersonal dynamics vividly. Users rapidly develop intimate, emotional attachments to these AI systems, often describing relationships with these bots as deeper or more supportive than comparable human interactions <cite id=\"f31x9\"><a href=\"#zotero%7C20283625%2FIW4H8XPJ\">(Fitzpatrick et al., 2017)</a></cite>. The absence of negative emotional displays or human-like inconsistencies from these AI systems further enhances the hyperpersonal effect, reinforcing idealized user perceptions <cite id=\"glj5n\"><a href=\"#zotero%7C20283625%2FEUI9BX43\">(Walther, 1996)</a></cite>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce351ad8-4e60-4e80-ac57-7d98d9591859",
   "metadata": {
    "citation-manager": {
     "citations": {
      "6y5xf": []
     }
    }
   },
   "source": [
    "## Ethical Considerations and Future Research Directions\n",
    "\n",
    "&ensp; &ensp; &ensp; The anthropomorphic and hyperpersonal nature of human-LLM interactions raises significant ethical concerns. Users' emotional reliance on LLMs may lead to dependency, potentially impacting their real-world social relationships negatively (Følstad & Brandtzaeg, 2020). Additionally, idealized perceptions can cause users to overestimate the AI’s actual capabilities, making them vulnerable to misinformation or uncritical acceptance of generated content <cite id=\"6y5xf\"><a href=\"#zotero%7C20283625%2FKPTREER4\">(Nordheim et al., 2019)</a></cite>.\n",
    "\n",
    "&ensp; &ensp; &ensp; Future research could explore how SIP theory might evolve with emerging AI technologies. Studies should examine the psychological impacts of prolonged AI interaction, including emotional dependency and isolation. Furthermore, investigating how transparency about AI limitations can balance anthropomorphism, maintaining engagement without misleading users, represents a promising research trajectory.\n",
    "\n",
    "&ensp; &ensp; &ensp; Applying SIP theory to human-LLM interactions provides valuable insights into how humans build and sustain relational connections with AI through textual exchanges. While highlighting significant benefits in terms of companionship and therapeutic support, this application also underscores critical ethical considerations requiring careful attention from researchers, designers, and policymakers. Future investigations must continue exploring these dynamics to enhance positive outcomes and mitigate potential risks.\n",
    "\n",
    "&ensp; &ensp; &ensp; Ultimately, as society becomes more intertwined with technology, integrating SIP theory with emerging AI applications is crucial in providing insights that will guide future ethical AI development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7498f5-420b-4c34-9bd4-33617ce08f31",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "<!-- BIBLIOGRAPHY START -->\n",
    "<div class=\"csl-bib-body\">\n",
    "</div>\n",
    "<!-- BIBLIOGRAPHY END -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162f9f7-f86a-46fc-b2f8-048e4d1f8b4b",
   "metadata": {},
   "source": [
    "<!-- BIBLIOGRAPHY START -->\n",
    "<div class=\"csl-bib-body\">\n",
    "</div>\n",
    "<!-- BIBLIOGRAPHY END -->\n",
    "Epley, N., Waytz, A., & Cacioppo, J. T. (2007). On seeing human: A three-factor theory of anthropomorphism. *Psychological Review, 114*(4), 864–886. https://doi.org/10.1037/0033-295X.114.4.864\n",
    "\n",
    "Fitzpatrick, K. K., Darcy, A., & Vierhile, M. (2017). Delivering cognitive behavior therapy to young adults via a conversational agent (Woebot): A randomized controlled trial. *JMIR Mental Health, 4*(2), e7785. https://doi.org/10.2196/mental.7785\n",
    "\n",
    "Følstad, A., & Brandtzaeg, P. B. (2020). Users’ experiences with chatbots: Findings from a questionnaire study. *Quality and User Experience, 5*(1), 3. https://doi.org/10.1007/s41233-020-00033-2\n",
    "\n",
    "Gambino, A., Fox, J., & Ratan, R. (2020). Building a stronger CASA: Extending the Computers Are Social Actors paradigm. *Human–Machine Communication, 1*(1). https://doi.org/10.30658/hmc.1.5\n",
    "\n",
    "Nordheim, C. B., Følstad, A., & Bjørkli, C. A. (2019). An initial model of trust in chatbots for customer service—Findings from a questionnaire study. *Interacting with Computers, 31*(3), 317–335. https://doi.org/10.1093/iwc/iwz022\n",
    "\n",
    "Skjuve, M., Følstad, A., Fostervold, K. I., & Brandtzaeg, P. B. (2021). My chatbot companion: A study of human–chatbot relationships. *International Journal of Human–Computer Studies, 149*, 102601. https://doi.org/10.1016/j.ijhcs.2021.102601\n",
    "\n",
    "Walther, J. B. (1996). Computer-mediated communication: Impersonal, interpersonal, and hyperpersonal interaction. *Communication Research, 23*(1), 3–43. https://doi.org/10.1177/009365096023001001\n",
    "\n",
    "Walther, J. B. (1992). Interpersonal effects in computer-mediated interaction: A relational perspective. *Communication Research, 19*(1), 52–90. https://doi.org/10.1177/009365092019001003\n",
    "\n",
    "(having issues with Zotero, manual bibliography)"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
